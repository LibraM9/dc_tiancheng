{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**导入所需库**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gensim\n",
    "import warnings\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier,GradientBoostingClassifier,ExtraTreesClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**读取数据**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(62767, 1509)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('../cache/features_add.csv')\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**特征选择**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "剔除特征nunique个数小于等于1的特征列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in data.columns:\n",
    "    if col not in ['UID', 'Tag']:\n",
    "        if data[col].nunique() <= 1:\n",
    "            del data[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calIV(df, val, target):\n",
    "    eps = 0.000001\n",
    "    gbi = pd.crosstab(df[val], df[target]) + eps\n",
    "    gb = df[target].value_counts() + eps\n",
    "    gbri = gbi / gb\n",
    "    gbri['woe'] = np.log(gbri[1]/gbri[0])\n",
    "    gbri['iv'] = (gbri[1]-gbri[0]) * gbri['woe']\n",
    "    return gbri['iv'].sum()\n",
    "\n",
    "def select_feature(clf,x_train,y_train,x_valid):\n",
    "    clf.fit(x_train.fillna(-99999), y_train)\n",
    "    model = SelectFromModel(clf, prefit=True, threshold=\"mean\")\n",
    "\n",
    "    x_train = model.transform(x_train.fillna(-99999))\n",
    "    x_valid = model.transform(x_valid.fillna(-99999))\n",
    "\n",
    "    return x_train,x_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iv_features_importance = {'col': [],\n",
    "#                           'iv_score': []}\n",
    "# for col in data.columns:\n",
    "#     if col not in ['UID', 'Tag']:\n",
    "#         iv_features_importance['col'].append(col)\n",
    "#         iv_features_importance['iv_score'].append(calIV(data, col, 'Tag'))\n",
    "# iv_features_importance = pd.DataFrame(iv_features_importance)\n",
    "# iv_features_importance = iv_features_importance.sort_values(by=['iv_score'], ascending=False)\n",
    "\n",
    "# n = int(data.shape[1]*0.8)\n",
    "# iv_important_features = list(iv_features_importance['col'][0:n].values)\n",
    "# data = data[iv_important_features+['UID', 'Tag']]\n",
    "# data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data[data['Tag']!=0.5].copy()\n",
    "test = data[data['Tag']==0.5].copy()\n",
    "y_train = train['Tag']\n",
    "feats = [f for f in train.columns if f not in ['UID', 'Tag']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf=RandomForestClassifier()\n",
    "x_train,x_valid=select_feature(clf,train[feats],train['Tag'], test[feats])\n",
    "train=pd.DataFrame(x_train)\n",
    "test=pd.DataFrame(x_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats = [f for f in train.columns if f not in ['UID', 'Tag']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**评测函数**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tpr_weight_funtion(y_true,y_predict):\n",
    "    d = pd.DataFrame()\n",
    "    d['prob'] = list(y_predict)\n",
    "    d['y'] = list(y_true)\n",
    "    d = d.sort_values(['prob'], ascending=[0])\n",
    "    y = d.y\n",
    "    PosAll = pd.Series(y).value_counts()[1]\n",
    "    NegAll = pd.Series(y).value_counts()[0]\n",
    "    pCumsum = d['y'].cumsum()\n",
    "    nCumsum = np.arange(len(y)) - pCumsum + 1\n",
    "    pCumsumPer = pCumsum / PosAll\n",
    "    nCumsumPer = nCumsum / NegAll\n",
    "    TR1 = pCumsumPer[abs(nCumsumPer-0.001).idxmin()]\n",
    "    TR2 = pCumsumPer[abs(nCumsumPer-0.005).idxmin()]\n",
    "    TR3 = pCumsumPer[abs(nCumsumPer-0.01).idxmin()]\n",
    "    return 0.4 * TR1 + 0.3 * TR2 + 0.3 * TR3\n",
    "\n",
    "def eval_function(y_predict,dtrain):\n",
    "    y_true = dtrain.get_label()\n",
    "    d = pd.DataFrame()\n",
    "    d['prob'] = list(y_predict)\n",
    "    d['y'] = list(y_true)\n",
    "    d = d.sort_values(['prob'], ascending=[0])\n",
    "    y = d.y\n",
    "    PosAll = pd.Series(y).value_counts()[1]\n",
    "    NegAll = pd.Series(y).value_counts()[0]\n",
    "    pCumsum = d['y'].cumsum()\n",
    "    nCumsum = np.arange(len(y)) - pCumsum + 1\n",
    "    pCumsumPer = pCumsum / PosAll\n",
    "    nCumsumPer = nCumsum / NegAll\n",
    "    TR1 = pCumsumPer[abs(nCumsumPer-0.001).idxmin()]\n",
    "    TR2 = pCumsumPer[abs(nCumsumPer-0.005).idxmin()]\n",
    "    TR3 = pCumsumPer[abs(nCumsumPer-0.01).idxmin()]\n",
    "    return 'tpr', 0.4 * TR1 + 0.3 * TR2 + 0.3 * TR3, True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LightGBM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 贝叶斯调参后的最优参数\n",
    "parameters = {'boosting_type': 'gbdt',\n",
    "              'objective': 'binary',\n",
    "              'learning_rate': 0.04,\n",
    "              'metric': 'binary_logloss',\n",
    "              'num_leaves': 112,\n",
    "              'max_depth': 6,\n",
    "              'feature_fraction': 0.7,\n",
    "              'bagging_fraction': 0.77,\n",
    "              'subsample_freq': 1,\n",
    "              'seed': 666,\n",
    "              'verbose': -1,\n",
    "              'n_jobs': 10,\n",
    "              'lambda_l2': 0.84,\n",
    "              'lambda_l1': 7.68,\n",
    "#               'max_bin': 310\n",
    "              }\n",
    "folds = StratifiedKFold(n_splits=5, shuffle=True, random_state=666)\n",
    "xx_submit = []\n",
    "xx_tpr = []\n",
    "xx_auc = []\n",
    "xx_iteration = []\n",
    "oof_preds = np.zeros(train.shape[0])\n",
    "feature_importance_df = pd.DataFrame()\n",
    "\n",
    "for n_fold, (train_idx, valid_idx) in enumerate(folds.split(train[feats], train['Tag'])):\n",
    "    dtrain = lgb.Dataset(data=train[feats].iloc[train_idx],\n",
    "                         label=train['Tag'].iloc[train_idx])\n",
    "    dvalid = lgb.Dataset(data=train[feats].iloc[valid_idx],\n",
    "                         label=train['Tag'].iloc[valid_idx])\n",
    "    clf = lgb.train(\n",
    "        params=parameters,\n",
    "        train_set=dtrain,\n",
    "        num_boost_round=2000,\n",
    "        valid_sets=[dvalid],\n",
    "        early_stopping_rounds=100,\n",
    "        verbose_eval=False,\n",
    "#         feval=eval_function\n",
    "    )\n",
    "    # save feature's importance\n",
    "    fold_importance_df = pd.DataFrame()\n",
    "    fold_importance_df[\"feature\"] = feats\n",
    "    fold_importance_df[\"importance\"] = clf.feature_importance()\n",
    "    fold_importance_df[\"fold\"] = n_fold + 1\n",
    "    feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis = 0)\n",
    "    valid_preds = clf.predict(train[feats].iloc[valid_idx], num_iteration=clf.best_iteration)\n",
    "    print('Fold%2d LOGLOSS: %.6f' % (n_fold + 1, clf.best_score['valid_0']['binary_logloss']), 'Fold%2d TPR: %.6f' % (n_fold + 1, tpr_weight_funtion(train['Tag'][valid_idx], valid_preds)))\n",
    "    xx_auc.append(clf.best_score['valid_0']['binary_logloss'])\n",
    "    xx_tpr.append(tpr_weight_funtion(train['Tag'][valid_idx], valid_preds))\n",
    "    xx_iteration.append(clf.best_iteration)\n",
    "    xx_submit.append(clf.predict(test[feats], num_iteration=clf.best_iteration))\n",
    "    oof_preds[valid_idx] = clf.predict(train[feats].iloc[valid_idx], num_iteration=clf.best_iteration)\n",
    "\n",
    "print('特征个数:%d' % (len(feats)))\n",
    "print('线下平均LOGLOSS:%.5f' % (np.mean(xx_auc)))\n",
    "print('线下全集TPR:%.5f' % (tpr_weight_funtion(train['Tag'], oof_preds)))\n",
    "print('线下平均TPR:%.5f' % (np.mean(xx_tpr)))\n",
    "print('线下平均迭代次数:%d' % (np.mean(xx_iteration)))\n",
    "print(xx_iteration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**特征重要性**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_importances(feature_importance_df_):\n",
    "    cols = feature_importance_df_[[\"feature\", \"importance\"]].groupby(\"feature\").mean().sort_values(by = \"importance\", ascending = False)[:50].index\n",
    "    best_features = feature_importance_df_.loc[feature_importance_df_.feature.isin(cols)]\n",
    "    plt.figure(figsize = (15, 10))\n",
    "    sns.barplot(x = \"importance\", y = \"feature\", data = best_features.sort_values(by = \"importance\", ascending = False))\n",
    "    plt.title('LightGBM Features (avg over folds)')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('../cache/lgbm_importances.png')\n",
    "display_importances(feature_importance_df)\n",
    "feature_importance_df.to_csv('../cache/feature_importance_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**提交结果**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 0\n",
    "for i in xx_submit:\n",
    "    s = s + i\n",
    "\n",
    "test['Tag'] = list(s / 5)\n",
    "test = data[data['Tag']==0.5].copy()\n",
    "submission = test[['UID', 'Tag']]\n",
    "submission[['UID', 'Tag']].to_csv(\"../submission/lgb_basesub.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
